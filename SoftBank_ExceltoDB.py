import pandas as pd
import pyodbc
import logging
from sendEmail import Email
import datetime
import unicodedata

def normalize_to_halfwidth(text):
    """å°‡æ–‡å­—è½‰ç‚ºåŠå‹ï¼ˆåŒ…å«ç‰¹æ®Šç¬¦è™Ÿè™•ç†ï¼‰"""
    if not isinstance(text, str):
        return text
    # åŸºæœ¬åŠå‹è½‰æ›
    text = unicodedata.normalize('NFKC', text)
    
    # ç‰¹æ®Šç¬¦è™Ÿè™•ç†ï¼ˆä¾‹ï¼šå…¨å½¢ç ´æŠ˜è™Ÿã€å…¨å½¢ç©ºç™½ç­‰ï¼‰
    text = text.replace('ï¼', '-')  # å…¨å½¢ç ´æŠ˜è™Ÿ
    text = text.replace('ã€€', ' ')  # å…¨å½¢ç©ºç™½
    text = text.replace('â€', '-')   # ç‰¹æ®Š Hyphen U+2010 
    return text
 
def setup_logging():
    """è¨­å®šæ—¥èªŒç³»çµ±"""
    current_datetime = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M")
    fn = f"logfile_{current_datetime}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(fn, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return fn


def connect_to_database(server, database):
    """é€£æ¥è³‡æ–™åº«"""
    try:
        conn = pyodbc.connect(
            f"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection=yes"
        )
        logging.info(f"æˆåŠŸé€£ç·šåˆ°è³‡æ–™åº«: {server}/{database}")
        return conn
    except Exception as e:
        logging.error(f"è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
        raise


def create_or_clear_table(cursor, table_name, column_mappings, sheet_name):
    """å‰µå»ºæˆ–æ¸…ç©ºè¡¨æ ¼"""
    try:
        cursor.execute(f"IF OBJECT_ID(N'{table_name}', N'U') IS NOT NULL SELECT 1 ELSE SELECT 0")
        table_exists = cursor.fetchone()[0]

        if table_exists == 0:
            # å»ºç«‹è¡¨æ ¼
            sql = f"CREATE TABLE {table_name} (\n"
            
            # ç‚º Orderinfo æ·»åŠ è‡ªå‹•å¢é•·ä¸»éµ
            if sheet_name == 'Orderinfo':
                sql += "OrderinfoNumber INT IDENTITY(1,1) PRIMARY KEY,\n"
            
            # æ·»åŠ å…¶ä»–æ¬„ä½
            for excel_col, (db_col, db_type) in column_mappings[sheet_name].items():
                if (sheet_name == 'CustomerCode' and excel_col == 'ASPæ–½å·¥åº—') or \
                   (sheet_name == 'FactoryShipment' and excel_col == 'PartNo_ETA_FLTC') or \
                   (sheet_name == 'Productinfo' and excel_col == 'Delta_PartNO'):
                    sql += f"[{db_col}] {db_type} PRIMARY KEY,\n"
                else:
                    sql += f"[{db_col}] {db_type},\n"
            
            sql = sql.rstrip(',\n') + "\n);"
            cursor.execute(sql)
            logging.info(f"âœ“ {sheet_name} è¡¨æ ¼å»ºç«‹å®Œæˆ")
        else:
            cursor.execute(f"DELETE FROM {table_name};")
            logging.info(f"âœ“ {sheet_name} è¡¨æ ¼è³‡æ–™å·²æ¸…é™¤")

    except Exception as e:
        logging.error(f"è™•ç†è¡¨æ ¼ {table_name} å¤±æ•—: {e}")
        raise


def process_factory_shipment_data(df):
    """è™•ç† FactoryShipment ç‰¹æ®Šé‚è¼¯"""
    # è™•ç†æ—¥æœŸæ¬„ä½
    date_columns = ['PO_Date', 'Actual_Ex_fac_date', 'ETD_SH', 'ETA_FLTC', 'Original_ETA']
    for col in date_columns:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors='coerce')
    
    # è™•ç†æ•¸é‡æ¬„ä½
    df['Qty'] = pd.to_numeric(df['Qty'], errors='coerce')
    
    # å¡«è£œ ETA_Year ç©ºå€¼
    df['ETA_Year'] = df['ETA_Year'].fillna(df['ETA_FLTC'].dt.year.astype(str))
    
    # æ¸…ç† Part_Noï¼ˆæ³¨æ„ï¼šé€™è£¡ä¸å†ä½¿ç”¨ normalize_textï¼Œå› ç‚º FactoryShipment ä¸åœ¨æ¨™æº–åŒ–æ¸…å–®ä¸­ï¼‰
    df['Part_No'] = df['Part_No'].astype(str).str.strip()
    df['PartNo_ETA_FLTC'] = df['Part_No'].astype(str) + df['ETA_FLTC'].astype(str)
    
    # æŒ‰è¤‡åˆéµåˆ†çµ„åˆä½µæ•¸æ“š
    return df.groupby('PartNo_ETA_FLTC', as_index=False).agg({
        'PO_Date': 'first', 'Item': 'first', 'Qty': 'sum', 'PO_NO': 'first',
        'Part_No': 'first', 'Actual_Ex_fac_date': 'first', 'ETD_SH': 'first',
        'ETA_FLTC': 'first', 'Original_ETA': 'first', 'ship_method': 'first',
        'ETA_Year': 'first', 'Status': 'first'
    })


def insert_data(cursor, table_name, df, column_mappings, sheet_name):
    # æº–å‚™æ¬„ä½æ˜ å°„ï¼ˆæ’é™¤è‡ªå‹•å¢é•·æ¬„ä½ï¼‰
    valid_columns = [col for col in df.columns if col in column_mappings[sheet_name]]
    db_columns = [f"[{column_mappings[sheet_name][col][0]}]" for col in valid_columns]
    
    # ç”Ÿæˆ INSERT èªå¥
    placeholders = ", ".join(["?"] * len(valid_columns))
    insert_sql = f"INSERT INTO {table_name} ({', '.join(db_columns)}) VALUES ({placeholders})"
    
    success_count = 0
    error_count = 0
    
    for index, row in df.iterrows():
        # æº–å‚™è³‡æ–™ï¼ˆå°‡ NaN è½‰ç‚º Noneï¼Œä¸¦çµ±ä¸€è½‰åŠå‹ï¼‰
        data = []
        for col in valid_columns:
            value = row[col]
            if pd.isna(value):
                data.append(None)
            elif isinstance(value, str):
                data.append(normalize_to_halfwidth(value.strip()))
            else:
                data.append(value)
                
        try:
            cursor.execute(insert_sql, tuple(data))
            success_count += 1
            
        except pyodbc.IntegrityError:
            error_count += 1
            logging.warning(f"âŒ {sheet_name} ç¬¬ {index+1} è¡Œï¼šé‡è¤‡ä¸»éµå€¼")
            
        except Exception as e:
            error_count += 1
            logging.error(f"âŒ {sheet_name} ç¬¬ {index+1} è¡Œæ’å…¥å¤±æ•—: {e}")
            logging.error(f"   è³‡æ–™: {dict(zip(valid_columns, data))}")
    
    logging.info(f"âœ“ {sheet_name}: æˆåŠŸæ’å…¥ {success_count} ç­†ï¼Œå¤±æ•— {error_count} ç­†")
    return success_count, error_count



def process_excel_to_sql(excel_file_path, table_mapping, column_mappings):
    """ä¸»è™•ç†å‡½æ•¸"""
    conn = None
    cursor = None
    total_success = 0
    total_errors = 0
    
    try:
        conn = connect_to_database('jpdejitdev01', 'ITQAS2')
        cursor = conn.cursor()

        for sheet_name, table_name in table_mapping.items():
            logging.info(f"ğŸ“Š è™•ç†å·¥ä½œè¡¨: {sheet_name}")
            
            # è®€å– Excel è³‡æ–™
            df = pd.read_excel(excel_file_path, sheet_name=sheet_name)
            
            # ç‰¹æ®Šè™•ç† FactoryShipment
            if sheet_name == 'FactoryShipment':
                df = process_factory_shipment_data(df)
            
            # å»ºç«‹æˆ–æ¸…ç©ºè¡¨æ ¼
            create_or_clear_table(cursor, table_name, column_mappings, sheet_name)
            
            # æ’å…¥è³‡æ–™
            success, errors = insert_data(cursor, table_name, df, column_mappings, sheet_name)
            total_success += success
            total_errors += errors

        conn.commit()
        logging.info(f"ğŸ‰ è™•ç†å®Œæˆï¼ç¸½è¨ˆï¼šæˆåŠŸ {total_success} ç­†ï¼Œå¤±æ•— {total_errors} ç­†")

    except Exception as e:
        logging.error(f"ğŸ’¥ è™•ç†éç¨‹ä¸­å‡ºç¾éŒ¯èª¤: {e}")
        if conn:
            conn.rollback()
        raise
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()


def send_notification_email(log_filename):
    """ç™¼é€é€šçŸ¥éƒµä»¶"""
    try:
        sender_email = "SRV.ITREMIND.RBT@deltaww.com"
        password = "Dej1tasd"
        email = Email()
        subject = "SoftBank_Update_dataBase"
        body = "SoftBank è³‡æ–™åº«æ›´æ–°å®Œæˆï¼Œè©³ç´°è¨˜éŒ„è«‹åƒè€ƒé™„ä»¶ã€‚"
        
        for recipient in ['boris.wang@deltaww.com']:
            email.send_email(sender_email, password, recipient, subject, body, log_filename)
        
        logging.info("âœ‰ï¸ é€šçŸ¥éƒµä»¶ç™¼é€å®Œæˆ")
    except Exception as e:
        logging.error(f"ğŸ“§ éƒµä»¶ç™¼é€å¤±æ•—: {e}")


if __name__ == "__main__":
    # è¨­å®šæ—¥èªŒ
    log_filename = setup_logging()
    
    # é…ç½®åƒæ•¸
    excel_file_path = r'\\jpdejstcfs01\\STC_share\\JP IT\STC SBK ä»•åˆ†ã‘ãƒªã‚¹ãƒˆ\\IT system\\SoftBankData_DBusing_test1 kae_20250528.xlsx'
    
    table_mapping = {
        'CustomerCode': 'dbo.SoftBank_Data_CustomerCode',
        'FactoryShipment': 'dbo.SoftBank_Data_FactoryShipment',
        'Orderinfo': 'dbo.SoftBank_Data_Orderinfo',
        'Productinfo': 'dbo.SoftBank_Data_Productinfo'
    }
    
    # åˆ—æ˜ å°„é…ç½®
    column_mappings = {
        'CustomerCode': {
            'ASPæ–½å·¥åº—': ('ASP', 'NVARCHAR(255)'), 
            'Customer code': ('Customer_code', 'NVARCHAR(255)')
        },
        'FactoryShipment': {
            'PartNo_ETA_FLTC': ('PartNo_ETA_FLTC', 'NVARCHAR(255)'),
            'PO_Date': ('PO_Date', 'DATE'),
            'Item': ('Item', 'NVARCHAR(255)'),
            'PO_NO': ('PO_NO', 'NVARCHAR(255)'),
            'Part_No': ('Part_No', 'NVARCHAR(255)'),
            'Qty': ('Qty', 'INT'),
            'Actual_Ex_fac_date': ('Actual_Ex_fac_date', 'DATE'),
            'ETD_SH': ('ETD_SH', 'DATE'),
            'ETA_FLTC': ('ETA_FLTC', 'DATE'),
            'Original_ETA': ('Original_ETA', 'DATE'),
            'ship_method': ('ship_method', 'NVARCHAR(255)'),
            'ETA_Year': ('ETA_Year', 'NVARCHAR(255)'),
            'Status': ('Status', 'NVARCHAR(255)')
        },  
        'Orderinfo': {
            'æ³¨æ–‡æ›¸å—é ˜': ('Purchase_Order_Received', 'NVARCHAR(255)'),
            'Pull in å±¥æ­´': ('Pull_in_History', 'NVARCHAR(255)'),
            'è¦‹ç©æ›¸å›ç­”çŠ¶æ³': ('Quotation_reply_status', 'NVARCHAR(255)'),
            'æ³¨æ–‡æ—¥': ('Order_Date', 'DATE'),
            'DEJè¦‹ç©ã‚Šç•ªå·': ('DEJ_Estimate_Number', 'NVARCHAR(255)'),
            'æ³¨æ–‡æ›¸': ('Quotation_status', 'NVARCHAR(255)'),
            'å¯¦éš›å‡ºè·æ—¥': ('Actual_Shipment_Date', 'DATE'),
            'é è¨ˆå‡ºè·æ—¥': ('Estimated_Shipment_Date', 'DATE'),
            'ç´å“æ—¥': ('Delivery_Date', 'DATE'),
            'å¸Œæœ›ç´æœŸ': ('Desired_Delivery_Date', 'NVARCHAR(255)'),
            'æ¨™æº–ç´æœŸ': ('Standard_Delivery_Date', 'NVARCHAR(255)'),
            'å·¥äº‹å/å±€å': ('Station_Name', 'NVARCHAR(255)'),
            'å“åãƒ»è¦æ ¼(PSI)': ('Product_Name_PSI', 'NVARCHAR(255)'),
            'SET': ('SET', 'NVARCHAR(255)'),
            'FOC/Option': ('FOC/Option', 'NVARCHAR(255)'),
            'å“åãƒ»è¦æ ¼': ('Product_Name', 'NVARCHAR(255)'),
            'å°æ•°': ('Quantity', 'INT'),
            'ç™ºæ³¨å…ˆ': ('OrdererLocation', 'NVARCHAR(255)'),
            'æ‹…å½“è€…': ('Person_in_Charge', 'NVARCHAR(255)'),
            'é€ã‚Šå…ˆ': ('Recipient', 'NVARCHAR(255)'),
            'é€£çµ¡äºº': ('Contact_Person', 'NVARCHAR(255)'),
            'ä½æ‰€': ('Contact_Address', 'NVARCHAR(255)'),
            'é›»è©±': ('ContactPhone', 'NVARCHAR(255)'),
            'è¨»': ('ContactNotes', 'NVARCHAR(255)'),
            'SOï¼ƒ': ('SO_NO', 'NVARCHAR(255)'),
            'DNï¼ƒ': ('DN_NO', 'NVARCHAR(255)'),
            'CustomerCode': ('CustomerCode', 'NVARCHAR(255)'),
            'å–®åƒ¹': ('Unitprice', 'NVARCHAR(255)'),
            'è¦‹ç©ã‚Šï¼„(è«‹æ±‚ç¨æŠœã)': ('QuotationPrice', 'NVARCHAR(255)'),
            'è¦‹ç©ã‚Šï¼„(è«‹æ±‚ç¨è¾¼ã¿)': ('QuotationPrice_with_tax', 'NVARCHAR(255)'),
            'é€ã‚ŠçŠ¶ç•ªå·': ('Invoice_Number', 'NVARCHAR(255)')
        },
        'Productinfo': {
            'Delta_PartNO': ('Delta_PartNO', 'NVARCHAR(255)'),
            'Remark': ('Remark', 'NVARCHAR(255)'),
            'Category': ('Category', 'NVARCHAR(255)'),
            '1SET10PCS': ('1SET10PCS', 'NVARCHAR(255)'),
            'Customer_Model_Name': ('Customer_Model_Name', 'NVARCHAR(255)'),
            'Model': ('Model', 'NVARCHAR(255)'),
            'ç¨æŠœå˜ä¾¡': ('UnitPrice', 'INT'),
            'æ¨™æº–ç´æœŸ': ('Standard_Delivery_Time', 'INT'),
            'æœˆæœ«SAPåº«å­˜': ('Month-End_SAP_Inventory', 'INT')
        }
    }

    # åŸ·è¡Œä¸»ç¨‹å¼
    try:
        logging.info("ğŸš€ é–‹å§‹è™•ç† SoftBank è³‡æ–™åº«æ›´æ–°ï¼ˆå¼·åŒ–å…¨è§’åŠè§’æ¨™æº–åŒ–ç‰ˆæœ¬ï¼‰")
        process_excel_to_sql(excel_file_path, table_mapping, column_mappings)
        send_notification_email(log_filename)
        
    except Exception as e:
        logging.error(f"ğŸ’¥ ç¨‹å¼åŸ·è¡Œå¤±æ•—: {e}")
        send_notification_email(log_filename)  # å³ä½¿å¤±æ•—ä¹Ÿç™¼é€éƒµä»¶é€šçŸ¥